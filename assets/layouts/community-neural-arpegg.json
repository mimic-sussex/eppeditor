[{"2":{"fixed":false,"resizable":true,"draggable":true,"customDragger":false,"customResizer":false,"min":{"w":1,"h":1},"max":{},"x":0,"y":0,"w":1,"h":2},"3":{"fixed":false,"resizable":true,"draggable":true,"customDragger":false,"customResizer":false,"min":{"w":1,"h":1},"max":{},"x":0,"y":0,"w":2,"h":2},"6":{"fixed":false,"resizable":true,"draggable":true,"customDragger":false,"customResizer":false,"min":{"w":1,"h":1},"max":{},"x":0,"y":0,"w":4,"h":3},"8":{"fixed":false,"resizable":true,"draggable":true,"customDragger":false,"customResizer":false,"min":{"w":1,"h":1},"max":{},"x":0,"y":0,"w":4,"h":4,"id":"_v16k8ccf3"},"12":{"fixed":false,"resizable":true,"draggable":true,"customDragger":false,"customResizer":false,"min":{"w":1,"h":1},"max":{},"x":0,"y":0,"w":8,"h":5},"id":"_v16k8ccf3","data":{"id":"_v16k8ccf3","type":"liveCodeEditor","name":"liveCodeEditor_v16k8ccf3","background":"#151515","lineNumbers":true,"hasFocus":true,"theme":"icecoder","grammarSource":"/languages/default/grammar.ne","liveCodeSource":"","content":"//Tempo\n{120, 4}clk;\n\n//The pattern (received from ML)\n:pat:{1}fromJS;\n\n//The mouse coordinates (sent to ML)\n{{10}imp, 0, [{}mouseX, {}mouseY],2}toJS;\n\n//Play the pattern\n:freq:{{8}clp, [1], :pat:}rsq;\n>{:freq:}tri;","grammar":"# Lexer [or tokenizer] definition with language lexemes [or tokens]\n@{%\n\nconst lexer = moo.compile({\n  separator:      /,/,\n  paramEnd:       /}/,\n  paramBegin:     /{/,\n  listEnd:        /\\]/,\n  listBegin:      /\\[/,\n  dacoutCh:       /\\>[0-9]+/,\n  dacout:         /\\>/,\n  variable:       /:[a-zA-Z0-9]+:/,\n  sample:         { match: /\\\\[a-zA-Z0-9]+/, lineBreaks: true, value: x => x.slice(1, x.length)},\n  slice:          { match: /\\|[a-zA-Z0-9]+/, lineBreaks: true, value: x => x.slice(1, x.length)},\n  stretch:        { match: /\\@[a-zA-Z0-9]+/, lineBreaks: true, value: x => x.slice(1, x.length)},\n  clockTrig:      /0t-?(?:[0-9]|[1-9][0-9]+)(?:\\.[0-9]+)?\\b/,\n\tnumber:         /-?(?:[0-9]|[1-9][0-9]+)(?:\\.[0-9]+)?\\b/,\n  semicolon:      /;/,\n  funcName:       /[a-zA-Z][a-zA-Z0-9]*/,\n\tstring:\t\t\t\t\t{ match: /'[a-zA-Z0-9]+'/, value: x => x.slice(1,x.length-1)},\n  comment:        /\\/\\/[^\\n]*/,\n  ws:             { match: /\\s+/, lineBreaks: true},\n});\n\n%}\n\n# Pass your lexer object using the @lexer option\n@lexer lexer\n\n# Grammar definition in the Extended Backus Naur Form (EBNF)\nmain -> _ Statement _\n{% d => ( { '@lang' : d[1] } )  %}\n\nStatement ->\n  %comment _ Statement\n  {% d => d[2] %}\n\t|\n  Expression _ %semicolon _ Statement\n  {% d => [ { '@spawn': d[0] } ].concat(d[4]) %}\n  |\n  Expression _ %semicolon (_ %comment):*\n  {% d => [ { '@spawn': d[0] } ] %}\n\n\nExpression ->\n  ParameterList _ %funcName\n  {% d => sema.synth( d[2].value, d[0]['@params'] ) %}\n  |\n  ParameterList _ %sample\n  {% d => sema.synth( 'sampler', d[0]['@params'].concat( [ sema.str( d[2].value ) ] ) ) %}\n  |\n  ParameterList _ %slice\n  {% d => sema.synth( 'slice', d[0]['@params'].concat( [ sema.str( d[2].value ) ] ) ) %}\n  |\n  ParameterList _ %stretch\n  {% d => sema.synth( 'stretch', d[0]['@params'].concat( [ sema.str( d[2].value ) ] ) ) %}\n  |\n  %variable _ Expression\n  {% d => sema.setvar( d[0].value, d[2] ) %}\n  |\n  %dacout _ Expression\n  {% d => sema.synth( 'dac', [d[2]] ) %}\n  |\n  %dacoutCh _ Expression\n  {% d => sema.synth( 'dac', [d[2], sema.num(d[0].value.substr(1))] ) %}\n\nParameterList ->\n  %paramBegin Params %paramEnd\n  {% d => ( { 'paramBegin': d[0], '@params': d[1], 'paramEnd': d[2] } ) %}\n\t|\n\t%paramBegin _ %paramEnd\n  {% d => ( { 'paramBegin': d[0], '@params': [], 'paramEnd': d[2] } ) %}\n\n\nParams ->\n  ParamElement\n  {% d => ( [ d[0] ] ) %}\n  |\n  ParamElement _ %separator _ Params\n  {% d => [ d[0] ].concat(d[4]) %}\n\nParamElement ->\n  %number\n  {% d => ( { '@num': d[0] } ) %}\n\t|\n\t%string\n  {% d => ( { '@string': d[0].value } ) %}\n  |\n  Expression\n  {% id %}\n  |\n  %variable\n  {% d => sema.getvar( d[0].value ) %}\n  |\n  %listBegin Params  %listEnd\n  {% d => ( { '@list': d[1] } )%}\n\n\n# Whitespace\n\n_  -> wschar:*\n{% function(d) {return null;} %}\n\n__ -> wschar:+\n{% function(d) {return null;} %}\n\nwschar -> %ws\n{% id %}\n"},"hasFocus":true},{"2":{"fixed":false,"resizable":true,"draggable":true,"customDragger":false,"customResizer":false,"min":{"w":1,"h":1},"max":{},"x":1,"y":0,"w":1,"h":2},"3":{"fixed":false,"resizable":true,"draggable":true,"customDragger":false,"customResizer":false,"min":{"w":1,"h":1},"max":{},"x":2,"y":0,"w":1,"h":2},"6":{"fixed":false,"resizable":true,"draggable":true,"customDragger":false,"customResizer":false,"min":{"w":1,"h":1},"max":{},"x":0,"y":3,"w":3,"h":3},"8":{"fixed":false,"resizable":true,"draggable":true,"customDragger":false,"customResizer":false,"min":{"w":1,"h":1},"max":{},"x":0,"y":4,"w":2,"h":1,"id":"_rcwjyt5dr"},"12":{"fixed":false,"resizable":true,"draggable":true,"customDragger":false,"customResizer":false,"min":{"w":1,"h":1},"max":{},"x":8,"y":0,"w":4,"h":4},"id":"_rcwjyt5dr","data":{"id":"_rcwjyt5dr","type":"analyser","name":"analyser_rcwjyt5dr","background":"#191919","lineNumbers":true,"hasFocus":true,"theme":"icecoder","mode":""},"hasFocus":false},{"2":{"fixed":false,"resizable":true,"draggable":true,"customDragger":false,"customResizer":false,"min":{"w":1,"h":1},"max":{},"x":0,"y":2,"w":1,"h":2},"3":{"fixed":false,"resizable":true,"draggable":true,"customDragger":false,"customResizer":false,"min":{"w":1,"h":1},"max":{},"x":0,"y":2,"w":2,"h":2},"6":{"fixed":false,"resizable":true,"draggable":true,"customDragger":false,"customResizer":false,"min":{"w":1,"h":1},"max":{},"x":0,"y":6,"w":4,"h":3},"8":{"fixed":false,"resizable":true,"draggable":true,"customDragger":false,"customResizer":false,"min":{"w":1,"h":1},"max":{},"x":4,"y":0,"w":4,"h":5,"id":"_d828bn65a"},"12":{"fixed":false,"resizable":true,"draggable":true,"customDragger":false,"customResizer":false,"min":{"w":1,"h":1},"max":{},"x":0,"y":5,"w":8,"h":5},"id":"_d828bn65a","data":{"id":"_d828bn65a","type":"modelEditor","name":"modelEditor_d828bn65a","background":"#151515","lineNumbers":true,"hasFocus":true,"theme":"monokai","content":"importScripts(\"https://cdn.jsdelivr.net/npm/@tensorflow/tfjs/dist/tf.min.js\");\n____\n\nvar chanArp = createOutputChannel(1, 8);\n\nvar arp_from = [60, 64, 67, 72, 60, 64, 67, 72];\nvar arp_to = [72, 67, 72, 64, 72, 60, 72, 64];\n\nchanArp.send(mtof(arp_from));\n\n//Midi to frequency\nfunction mtof(arp) {\n    var freqs = [];\n    for (i = 0; i < arp.length; i++) {\n        freqs.push(Math.pow(2, (arp[i] - 69) / 12) * 440);\n    }\n    return freqs;\n}\n\n//Normalize midi int(0-127) -> float(0.0, 1.0)\nfunction norm(arp) {\n    var midi = [];\n    for (i = 0; i < arp.length; i++) {\n        midi.push(arp[i] / 127);\n    }\n    return midi;\n}\n\n//Denormalize midi float(0.0, 1.0) -> int(0-127)\nfunction denorm(arp) {\n    var midi = [];\n    for (i = 0; i < arp.length; i++) {\n        midi.push(Math.round(arp[i] * 127));\n    }\n    return midi;\n}\n\n\n____\n\n//LIFTED FROM THE TUTORIALS\n\n//Mouse\nvar mouseX = 0;\nvar mouseY = 0;\nvar mousePositions = [];\n\n//Modes for machine learning\nvar MLMODES = { NONE: 0, TRAIN: 1, PREDICT: 2 };\nvar mode = MLMODES.NONE;\n\n\n//record states as targets for the model\nvar states = [];\nvar inputMap = {\n    0: (x) => {\n        //record the mouse values\n        mouseX = x[0];\n        mouseY = x[1];\n        if (mode == MLMODES.TRAIN) {\n            mousePositions.push([mouseX, mouseY]);\n            states.push(norm(arp));\n            console.log(mousePositions.length, \"samples collected\");\n        } else if (mode == MLMODES.PREDICT) {\n            let modelInput = tf.tensor2d([mouseX, mouseY], [1, 2]);\n            let predicted_arp = model.predict(modelInput).dataSync();\n            chanArp.send(mtof(denorm(predicted_arp)));\n        }\n    },\n};\n\n//receive data from the LC window\ninput = (id, x) => {\n    if (inputMap[id]) {\n        inputMap[id](x);\n    }\n};\n\n\n\n________\n\n//FIRST ARPEGGIO\n//Train: Move mouse to the top left corner and run this section\n\nvar arp = [].concat(arp_from);\nchanArp.send(mtof(arp));\nmode = MLMODES.TRAIN;\n_____\n\n//Stop\nmode = MLMODES.NONE;\n\n\n\n________\n\n//SECOND ARPEGGIO\n//Train: Move mouse to the bottom right corner and run this section\n\nvar arp = [].concat(arp_to);\nchanArp.send(mtof(arp));\nmode = MLMODES.TRAIN;\n_____\n\n//Stop\nmode = MLMODES.NONE;\n_____\n\n\n\n\n//CREATE AND TRAIN MODEL\n\nvar model = tf.sequential();\nmodel.add(tf.layers.dense({\n    inputShape: [2],\n    units: 30,\n    activation: 'relu',\n    kernelInitialiser: 'leCunNormal'\n}));\nmodel.add(tf.layers.dense({ units: 30 }));\nmodel.add(tf.layers.dense({ units: arp.length }));\nmodel.compile({ loss: 'meanSquaredError', optimizer: tf.train.adam() });\n\nvar trainIn = tf.tensor2d(mousePositions, [mousePositions.length, 2]);\nvar trainOut = tf.tensor2d(states, [states.length, arp.length]);\n\nfunction onBatchEnd(x, logs) { console.log(x, \"Loss: \" + logs.loss) };\n\nmodel.fit(trainIn, trainOut, { epochs: 25, callbacks: { onBatchEnd } }).then(info => { console.log(info); });\n\n\n\n\n\n_____\n\n//PREDICT\n//Top left corner\nconsole.log(\"Expected:\");\nconsole.log(arp_from);\nconsole.log(\"Predicted:\");\nconsole.log(denorm(model.predict(tf.tensor2d([0.1, 0.1], [1, 2])).dataSync()));\n\n//Bottom right corner\nconsole.log(\"Expected:\");\nconsole.log(arp_to);\nconsole.log(\"Predicted:\");\nconsole.log(denorm(model.predict(tf.tensor2d([0.9, 0.9], [1, 2])).dataSync()));\n\n\nmode = MLMODES.PREDICT;"},"hasFocus":false}]