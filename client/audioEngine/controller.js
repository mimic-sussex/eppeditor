
// NOTE:FB We need this imports here for webpack to emit this modules from sema-engine package
import "sema-engine/sema-engine.wasmmodule.js";
import "sema-engine/open303.wasmmodule.js";
import "sema-engine/maxi-processor.js";
import "sema-engine/ringbuf.js";

import { PubSub } from "../messaging/pubSub.js";
import { audioEngineStatus } from "../stores/common.js";
/**
 * The Controller is a singleton class that encapsulates signal engine (sema-engine)
 * and implements the dependency inversion principle
 * @class AudioEngine
 */
export default class Controller {
	/**
	 * @constructor
	 */
	constructor(engine) {
		if (Controller.instance) {
			return Controller.instance; // Singleton pattern, only one instance in sema
		}
		Controller.instance = this;

		// Constructor dependency injection of a sema-engine singleton instance
		// TODO make this type abstract on Typescript
		this.engine = engine;

		this.samplesLoaded = false;

		this.messaging = new PubSub();

		this.messaging.subscribe("eval-dsp", async (e) => {
			this.engine.eval(e); // Also resumes engine playback if paused
		});

		this.messaging.subscribe("stop-audio", (e) => this.engine.stop());

		this.messaging.subscribe("load-sample", (name, url) =>
			this.engine.loadSample(name, url)
		);

		this.messaging.subscribe("add-engine-analyser", (e) =>
			this.engine.createAnalyser(e.id, (data) =>
				this.messaging.publish(`${e.id}-analyser-data`, data)
			)
		);

		this.messaging.subscribe("remove-engine-analyser", (e) =>
			this.engine.removeAnalyser(e)
		);

		this.messaging.subscribe("model-output-data", (e) =>
			this.engine.postAsyncMessageToProcessor(e)
		);
		this.messaging.subscribe("clock-phase", (e) =>
			this.engine.postAsyncMessageToProcessor(e)
		);
		this.messaging.subscribe("model-send-buffer", (e) =>
			this.engine.postAsyncMessageToProcessor(e)
		);

		this.messaging.subscribe("mouse-xy", (e) => {
			if (this.sharedArrayBuffers.mxy) {
				this.sharedArrayBuffers.mxy.rb.push(e);
			}
		});

		this.messaging.subscribe("osc", (e) =>
			console.log(`DEBUG:AudioEngine:OSC: ${e}`)
		);

		//the message has incoming data from other peers
		// this.messaging.subscribe("peermsg", (e) => {
		//   e.ttype = 'NET';
		//   e.peermsg = 1;
		//   this.onMessagingEventHandler(e);
		// });

		// this.messaging.subscribe("peerinfo-request", (e) => {
		// 	console.log(this.peerNet.peerID);
		// 	copyToPasteBuffer(this.peerNet.peerID);
		// });
	}


	/**
	 * Handler of the Pub/Sub message events
	 * whose topics are subscribed to in the audio engine constructor
	 * @onMessagingEventHandler
	 */
	onMessagingEventHandler(event) {
		if (event !== undefined) {
			// Receive notification from "model-output-data" topic
			console.log("DEBUG:AudioEngine:onMessagingEventHandler:");
			console.log(event);
			this.audioWorkletNode.port.postMessage(event);
		}
	}

	/**
	 * Handler of audio worklet processor events
	 * @engineEventHandler
	 */
	engineEventHandler(event) {
		if (event !== undefined && event.data !== undefined) {
			// console.log('DEBUG:AudioEngine:processorMessageHandler:');
			// console.log(event);
			if (event.data.rq !== undefined && event.data.rq === "send") {
				switch (event.data.ttype) {
					case "ML":
						// Stream generated by 'toJS' live code instruction — e.g. {10,0,{1}sin}toJS;
						// publishes to model/JS editor, which posts to ml.worker
						this.messaging.publish("model-input-data", {
							type: "model-input-data",
							value: event.data.value,
							ch: event.data.ch,
						});
						break;
					case "NET":
						this.peerNet.send(
							event.data.ch[0],
							event.data.value,
							event.data.ch[1]
						);
						break;
				}
			} else if (event.data.rq && event.data.rq === "buf") {
				console.log("buf", event.data);
				switch (event.data.ttype) {
					case "ML":
						this.messaging.publish("model-input-buffer", {
							type: "model-input-buffer",
							value: event.data.value,
							channelID: event.data.channelID, //channel ID
							blocksize: event.data.blocksize,
						});
						break;
				}
			} else if (event.data.phase !== undefined) {
				// console.log('DEBUG:AudioEngine:phase:');
				// console.log(event.data.phase);
				// this.kuraClock.broadcastPhase(event.data.phase); // TODO Refactor p to phase
			}
			// else if (event.data.rq != undefined && event.data.rq === 'receive') {
			//   switch (event.data.ttype) {
			//     case 'ML':
			//       // Stream generated by 'fromJS' live code instruction – e.g. {{10,1}fromJS}saw
			//       // publishes to model/JS editor, which posts to ml.worker
			//       this.messaging.publish('model-output-data-request', {
			//         type: 'model-output-data-request',
			//         value: event.data.value,
			//         channel: event.data.ch
			//       });
			//       break;
			//     case 'NET':
			//       break;
			//   }
			// }
		}
	}

	/**
	 * Initialises audio context and sets worklet processor code
	 * @play
	 */
	async init(audioWorkletURL /*numClockPeers*/) {

		if (this.engine !== undefined) {
			try {
				await this.engine.init(audioWorkletURL, this.engineEventHandler);

				// Connect Analysers loaded from the store need to pass callbacks after they load
				this.engine.connectAnalysers();

				const channelId = "mxy",
					ttype = "mouseXY",
					blockSize = 2;

				this.engine.createSharedArrayBuffer(channelId, ttype, blockSize);

				this.loadImportedSamples();

			} catch (error) {
				console.error("Error initialising engine");
			}
		}
	}

	onAudioInputFail(error) {
		console.log(
			`DEBUG:AudioEngine:AudioInputFail: ${error.message} ${error.name}`
		);
	}

	/**
	 * Sets up an AudioIn WAAPI sub-graph
	 * @connectMediaStreamSourceInput
	 */
	async connectMediaStream() {
		const constraints = (window.constraints = {
			audio: true,
			video: false,
		});

		navigator.mediaDevices
			.getUserMedia(constraints)
			.then((s) => this.onAudioInputInit(s))
			.catch(this.onAudioInputFail);
	}

	getSamplesNames() {
		const r = require.context("../../assets/samples", false, /\.wav$/);

		// return an array list of filenames (with extension)
		const importAll = (r) => r.keys().map((file) => file.match(/[^\/]+$/)[0]);

		return importAll(r);
	}

	lazyLoadSample(sampleName) {
		import(/* webpackMode: "lazy" */ `../../assets/samples/${sampleName}`)
			.then(() => this.engine.loadSample(sampleName, `/samples/${sampleName}`))
			.catch((err) =>
				console.error(`DEBUG:AudioEngine:lazyLoadSample: ` + err)
			);
	}

	loadImportedSamples() {
		this.getSamplesNames().forEach((sampleName) =>
			this.lazyLoadSample(sampleName)
		);

		this.samplesLoaded = true;
	}
}
